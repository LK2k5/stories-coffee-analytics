{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9ae09a-478e-4e24-a130-5264bca3a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "OUT_DIR = Path(\"../outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "(OUT_DIR / \"figures\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f75ca262-c956-441e-a813-9d786b9c6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_number(x):\n",
    "    \"\"\"Convert '1,234.56' -> 1234.56. Return NaN if not numeric.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().replace(\",\", \"\")\n",
    "    if s in [\"\", \"None\", \"nan\"]:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def normalize_branch(name):\n",
    "    \"\"\"Standardize branch names for matching across files.\"\"\"\n",
    "    if pd.isna(name) or name is None:\n",
    "        return None\n",
    "    s = str(name).lower().strip()\n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)   # remove punctuation\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()  # collapse spaces\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb048bc9-ceda-41e7-88f8-dc3c0b1c6a2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\rep_s_00673_SMRY.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m f4 = DATA_DIR / \u001b[33m\"\u001b[39m\u001b[33mrep_s_00673_SMRY.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df4_raw = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df4_raw.head(\u001b[32m20\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\EECE 490\\490 hacakthon\\stories-coffee-analytics\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\EECE 490\\490 hacakthon\\stories-coffee-analytics\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:300\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    297\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\EECE 490\\490 hacakthon\\stories-coffee-analytics\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1645\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1644\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\EECE 490\\490 hacakthon\\stories-coffee-analytics\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1904\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1902\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1903\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1904\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1915\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\EECE 490\\490 hacakthon\\stories-coffee-analytics\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:926\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    922\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    923\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    935\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\data\\\\rep_s_00673_SMRY.csv'"
     ]
    }
   ],
   "source": [
    "f4 = DATA_DIR / \"rep_s_00673_SMRY.csv\"\n",
    "df4_raw = pd.read_csv(f4)\n",
    "df4_raw.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a0f40-6f8c-4709-a79f-0689da450c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_raw.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac86b6-b47d-4239-a942-6847faa80501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68ef48-e5d4-4750-96bb-b9dd230aa650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_raw = df4_raw.rename(columns={\n",
    "    \"Stories\": \"Category\",\n",
    "    \"Unnamed: 1\": \"Qty\",\n",
    "    \"Unnamed: 2\": \"Total Price\",\n",
    "    \"Unnamed: 4\": \"Total Cost\",\n",
    "    \"Unnamed: 5\": \"Total Cost %\",\n",
    "    \"Unnamed: 6\": \"Total Profit\",\n",
    "    \"Unnamed: 8\": \"Total Profit %\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8ebca-20ee-4ced-a4e3-85d5b73a685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4_raw.copy()\n",
    "\n",
    "# drop rows where Category is empty\n",
    "df4 = df4[df4[\"Category\"].notna()].copy()\n",
    "\n",
    "# remove repeated export header rows\n",
    "df4 = df4[~df4[\"Category\"].astype(str).str.contains(\"Theoretical Profit\", case=False, na=False)]\n",
    "df4 = df4[~df4[\"Category\"].astype(str).str.contains(\"Page\", case=False, na=False)]\n",
    "df4 = df4[df4[\"Category\"].astype(str).str.strip() != \"Category\"]\n",
    "\n",
    "df4.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d0b693-7904-4f3a-93cf-3be5c17fab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4_raw.copy()\n",
    "\n",
    "# keep only rows where Category is not empty\n",
    "df4 = df4[df4[\"Category\"].notna()].copy()\n",
    "\n",
    "# remove export junk/header rows\n",
    "df4 = df4[~df4[\"Category\"].astype(str).str.contains(\"Theoretical Profit\", case=False, na=False)]\n",
    "df4 = df4[~df4[\"Category\"].astype(str).str.contains(\"Page\", case=False, na=False)]\n",
    "df4 = df4[~df4[\"Category\"].astype(str).str.match(r\"\\d{1,2}-[A-Za-z]{3}-\\d{2}\", na=False)]  # removes 22-Jan-26 style rows\n",
    "df4 = df4[df4[\"Category\"].astype(str).str.strip() != \"Category\"]  # removes the row that says Category Qty Total Price...\n",
    "\n",
    "df4.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b98bc-ca5f-453c-a507-95612edc432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a378a1-4020-47dc-8e93-671aebed21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows that are branch headers start with \"Stories\"\n",
    "is_branch_row = df4[\"Category\"].astype(str).str.lower().str.startswith(\"stories\")\n",
    "\n",
    "# create a helper column that has branch name only on branch rows\n",
    "df4[\"branch\"] = df4[\"Category\"].where(is_branch_row)\n",
    "\n",
    "# forward-fill branch downwards\n",
    "df4[\"branch\"] = df4[\"branch\"].ffill()\n",
    "\n",
    "df4[[\"Category\",\"branch\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f7ca8-a7a3-463f-be42-a6cbc58be22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4[df4[\"Category\"].isin([\"BEVERAGES\",\"FOOD\"])].copy()\n",
    "df4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe878a-90d1-43b3-925a-bfe3b9ab0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Qty\", \"Total Cost\", \"Total Profit\"]:\n",
    "    df4[col] = df4[col].apply(clean_number)\n",
    "\n",
    "df4[\"Revenue\"] = df4[\"Total Cost\"] + df4[\"Total Profit\"]\n",
    "df4[\"Profit_Margin\"] = df4[\"Total Profit\"] / df4[\"Revenue\"]\n",
    "df4[\"branch_norm\"] = df4[\"branch\"].apply(normalize_branch)\n",
    "\n",
    "df4[[\"branch\",\"Category\",\"Qty\",\"Total Cost\",\"Total Profit\",\"Revenue\",\"Profit_Margin\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc72d3-7c60-4b89-a17b-b703f049010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out4 = OUT_DIR / \"clean_category_summary.csv\"\n",
    "df4.to_csv(out4, index=False)\n",
    "print(\"Saved:\", out4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b849e8e-df8a-48d5-8dd2-fd040a9c4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape, df4[\"branch\"].nunique(), df4[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c3c33-6e33-481e-bfcc-63fac1342155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "f1 = DATA_DIR / \"REP_S_00134_SMRY.csv\"\n",
    "\n",
    "with open(f1, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    text1 = f.read()\n",
    "\n",
    "df1_raw = pd.read_csv(StringIO(text1), header=None)\n",
    "df1_raw.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef1e31-9222-4754-a222-59616392ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_raw.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc25d86-4ed2-4770-ac6b-0d69c1b76754",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(min(10, df1_raw.shape[1])):\n",
    "    sample = df1_raw[c].astype(str)\n",
    "    if sample.str.contains(\"Stories\", na=False).any():\n",
    "        print(\"Found 'Stories' in column:\", c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4327e5-707a-4f72-9eda-ddf9cd608ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH_COL = 1\n",
    "YEAR_COL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8dc20-4a71-4101-b841-a5892c1682c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH_COL = 1\n",
    "YEAR_COL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec49779-5c31-479e-9dcb-03375c590b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_raw.columns = [f\"c{i}\" for i in range(df1_raw.shape[1])]\n",
    "\n",
    "mask_branch = df1_raw[f\"c{BRANCH_COL}\"].astype(str).str.contains(\"Stories\", na=False)\n",
    "df1 = df1_raw[mask_branch].copy()\n",
    "\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f029ede8-ef85-4aef-9b5c-c4a335f6c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"year\"] = df1[f\"c{YEAR_COL}\"].replace(\"\", np.nan).ffill()\n",
    "df1[\"year\"] = df1[\"year\"].apply(clean_number).astype(\"Int64\")\n",
    "\n",
    "df1[[\"year\", f\"c{BRANCH_COL}\"]].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f738df-939a-4624-b5fe-ab43f615ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# make sure df1 exists and has year + c1 already\n",
    "df1 = df1.reset_index(drop=True)\n",
    "\n",
    "months = [\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "\n",
    "# Convert everything to numeric where possible (fast)\n",
    "num_df = df1.apply(lambda col: pd.to_numeric(col.astype(str).str.replace(\",\", \"\"), errors=\"coerce\"))\n",
    "\n",
    "# Extract first 12 numeric values per row\n",
    "vals = num_df.to_numpy()\n",
    "out = np.full((vals.shape[0], 12), np.nan)\n",
    "\n",
    "for i in range(vals.shape[0]):\n",
    "    rownums = vals[i][~np.isnan(vals[i])]\n",
    "    # remove year if it appears inside the numeric list\n",
    "    rownums = rownums[~np.isin(rownums, [2025, 2026])]\n",
    "    out[i, :min(12, len(rownums))] = rownums[:12]\n",
    "\n",
    "month_vals = pd.DataFrame(out, columns=months)\n",
    "\n",
    "df1_fast = pd.concat([df1, month_vals], axis=1)\n",
    "\n",
    "# quick view\n",
    "df1_fast[[\"year\", \"c1\", \"jan\", \"feb\", \"mar\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd460db-5a39-4316-9a2b-72b928488537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef2a3d-1363-41b6-bd3b-ac3e3f951759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382926f-10da-4cdf-b4ac-f3d9dd85f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35250c1b-e434-480f-b688-bb3ee48ec467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_raw = pd.read_csv(\"../data/REP_S_00134_SMRY.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12312a8-ddb7-494b-9ecf-e7a14f504175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_raw = pd.read_csv(r\"C:\\projects\\stories-coffee-analytics\\data\\REP_S_00134_SMRY.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22e949-9b9e-4aeb-b666-321f2bed3366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_raw.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1050c1-7785-4bbf-973f-7f9d30f81529",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a769b-fd8a-4f55-ab35-2f4a5a3fb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37dea1-1049-4069-9883-3365343e4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.apply(lambda col: col.map(clean_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cb573-c0e8-46fb-878a-32edfe1d93c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_number(x):\n",
    "    if x is None:\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float)):\n",
    "        return x\n",
    "    x = str(x).strip()\n",
    "    if x == \"\" or x.lower() in [\"nan\", \"none\"]:\n",
    "        return np.nan\n",
    "\n",
    "    # remove commas and any non-numeric characters (except . and -)\n",
    "    x = re.sub(r\"[^\\d\\.\\-]\", \"\", x)\n",
    "\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c606d8-5e31-46b3-8277-f7919e5f4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.apply(lambda col: col.map(clean_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c834ed-7c55-4ce2-abb5-116224d864ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da770c7-c7c8-40b0-81e0-9e9885f6ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3e3fd-2670-4bc6-a904-4332026744b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Repo root exists:\", Path(\"..\").resolve())\n",
    "print(\"Data files:\", list(Path(\"..\").glob(\"data/*.csv\"))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc493e-d940-4194-9003-21aa3b1f5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1_raw = pd.read_csv(\"../data/REP_S_00134_SMRY.csv\", header=None)\n",
    "df1_raw.shape, df1_raw.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d289a-ec2b-40cf-bab8-ca02c756d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_COL = 0\n",
    "BRANCH_COL = 1\n",
    "MONTH_START_COL = 3   # January\n",
    "MONTH_END_COL = 14    # exclusive end (we'll slice 3:15 for 12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361c7e9-2a87-478b-b928-70028fbb88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first row where YEAR_COL looks like 2025/2026 etc\n",
    "year_numeric = pd.to_numeric(df1_raw[YEAR_COL], errors=\"coerce\")\n",
    "start_idx = year_numeric.first_valid_index()\n",
    "start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e78970-c956-4623-b7d0-599df4491590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1_raw.loc[start_idx:].copy()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab9e38-fb6e-4c07-bb81-991a804d1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = pd.to_numeric(df[YEAR_COL], errors=\"coerce\").ffill().astype(\"Int64\")\n",
    "df[\"branch\"] = df[BRANCH_COL].where(\n",
    "    df[BRANCH_COL].astype(str).str.lower().str.startswith(\"stories\"),\n",
    "    np.nan\n",
    ").ffill()\n",
    "\n",
    "df[[\"year\",\"branch\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf350a9-6571-44cd-bfc0-afcf12248c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_block = df.loc[:, MONTH_START_COL:MONTH_END_COL-1].copy()\n",
    "\n",
    "# remove commas and convert\n",
    "month_block = month_block.replace({\",\": \"\"}, regex=True)\n",
    "month_block = month_block.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "month_block.head(5), month_block.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294540dd-be35-4947-8d09-d00785587674",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_block = df1.loc[4:, 3:14].copy()\n",
    "month_block.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbcd7e-e5c8-4c7b-8867-a4700b5b20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_block.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f05138-153c-4908-9f7c-f765dc623052",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "\n",
    "# take the raw month area (from col 3 onward), row 4 onward (your data rows)\n",
    "raw_month_area = df1.loc[4:, 3:].copy()\n",
    "\n",
    "def first_12_numbers(row):\n",
    "    vals = []\n",
    "    for x in row.values:\n",
    "        if pd.notna(x):\n",
    "            vals.append(float(x))\n",
    "    # pad / trim to exactly 12\n",
    "    vals = (vals + [np.nan]*12)[:12]\n",
    "    return pd.Series(vals, index=months)\n",
    "\n",
    "month_block = raw_month_area.apply(first_12_numbers, axis=1)\n",
    "month_block.shape, month_block.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bed875-146a-4559-92c5-0ef952ae6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_block.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8543015-a954-4909-b64a-a4d2a41a76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.copy()\n",
    "\n",
    "df[\"year\"] = df[0].ffill()\n",
    "df[\"branch\"] = df[1].ffill()\n",
    "\n",
    "# keep only real data rows (where we actually have a branch name)\n",
    "df_data = df.loc[4:].copy()\n",
    "df_data = df_data[df_data[\"branch\"].astype(str).str.lower().str.startswith(\"stories\")]\n",
    "df_data[[\"year\",\"branch\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260aeef4-47e2-4b77-b835-36b9297bd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.copy()\n",
    "df[\"year\"] = df[0].ffill()\n",
    "df[\"branch\"] = df[1].ffill()\n",
    "\n",
    "df.loc[0:25, [0, 1, \"year\", \"branch\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48522c-ecd6-499a-be5e-b1f2f97cf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "# start from raw again (NOT the cleaned df1 that changed types)\n",
    "df1_raw = pd.read_csv(r\"C:\\projects\\stories-coffee-analytics\\data\\REP_S_00134_SMRY.csv\", header=None)\n",
    "\n",
    "df = df1_raw.copy()\n",
    "\n",
    "# year is in col 0, branch name is in col 1 (based on your table)\n",
    "df[\"year_raw\"] = df[0]\n",
    "df[\"branch_raw\"] = df[1]\n",
    "\n",
    "df.loc[0:25, [0, 1, \"year_raw\", \"branch_raw\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe3dd1-fb7a-4799-8e87-21cc979b8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = pd.to_numeric(df[\"year_raw\"], errors=\"coerce\").ffill()\n",
    "df[\"branch\"] = df[\"branch_raw\"].astype(str)\n",
    "\n",
    "# keep only rows where branch starts with \"Stories\"\n",
    "mask = df[\"branch\"].str.lower().str.startswith(\"stories\")\n",
    "df_data = df.loc[mask].copy()\n",
    "\n",
    "df_data[[\"year\", \"branch\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31144750-4d96-4584-82b3-8c9df555e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the header row that contains \"January\"\n",
    "header_row = df1_raw.apply(lambda r: r.astype(str).str.contains(\"January\", case=False, na=False).any(), axis=1)\n",
    "header_idx = header_row[header_row].index[0]\n",
    "header_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6746b-b9f7-4d67-9313-648fe2d6686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_raw.loc[header_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0c8d7-ecd2-4131-acf8-aad7581f32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data[df_data[\"branch\"].astype(str).str.lower().str.startswith(\"stories\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb728ca-b151-43c2-918d-3504e6c63519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.copy()\n",
    "df[\"year\"] = df[0].ffill()\n",
    "df[\"branch\"] = df[1].ffill()\n",
    "\n",
    "df_tmp = df.loc[4:, [\"year\",\"branch\"]].reset_index(drop=True)\n",
    "df_tmp.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d6b99-fe4e-431c-b1f3-c0e463cfa433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"branch_str\"] = df_tmp[\"branch\"].astype(str).str.lower()\n",
    "df_tmp[\"has_stories\"] = df_tmp[\"branch_str\"].str.contains(\"stories\", na=False)\n",
    "\n",
    "df_tmp[\"has_stories\"].value_counts(), df_tmp[df_tmp[\"has_stories\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a600b5-88af-4a9e-8cf6-1f437231894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df.loc[4:].reset_index(drop=True).copy()\n",
    "\n",
    "# normalize branch text\n",
    "b = df_data[\"branch\"].astype(str).str.lower().str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "df_data = df_data[b.str.contains(r\"\\bstories\\b\", na=False)].reset_index(drop=True)\n",
    "df_data[[\"year\",\"branch\"]].head(10), df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fdc74-b3ea-4da6-831e-5d2d221e9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Reload raw (IMPORTANT: start from df1_raw, not df1 that got numeric-cleaned)\n",
    "df1_raw = pd.read_csv(r\"..\\data\\REP_S_00134_SMRY.csv\", header=None)\n",
    "\n",
    "# 2) Find the header row that contains \"January\"\n",
    "header_row = df1_raw.apply(lambda r: r.astype(str).str.contains(\"January\", case=False, na=False).any(), axis=1)\n",
    "header_idx = header_row[header_row].index[0]   # you already saw it's 3\n",
    "\n",
    "# 3) Keep only rows AFTER header row\n",
    "raw = df1_raw.loc[header_idx+1:].reset_index(drop=True).copy()\n",
    "\n",
    "# 4) Build year + branch from ORIGINAL text columns (0 and 1)\n",
    "raw[\"year\"] = pd.to_numeric(raw[0], errors=\"coerce\").ffill()\n",
    "raw[\"branch\"] = raw[1].astype(str).replace(\"nan\", np.nan).ffill()\n",
    "\n",
    "# 5) Month columns are 3..11 in your mapping (Jan..Sep)\n",
    "month_map = {'jan':3,'feb':4,'mar':5,'apr':6,'may':7,'jun':8,'jul':9,'aug':10,'sep':11}\n",
    "months = list(month_map.keys())\n",
    "\n",
    "def clean_number(x):\n",
    "    if pd.isna(x): \n",
    "        return np.nan\n",
    "    s = str(x).strip().replace(\",\", \"\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "for m, col in month_map.items():\n",
    "    raw[m] = raw[col].map(clean_number)\n",
    "\n",
    "# 6) Keep only real branch rows\n",
    "clean_monthly = raw[raw[\"branch\"].astype(str).str.lower().str.contains(\"stories\", na=False)].copy()\n",
    "\n",
    "# 7) Total + preview\n",
    "clean_monthly[\"total_calc\"] = clean_monthly[months].sum(axis=1, skipna=True)\n",
    "\n",
    "clean_monthly[[\"year\",\"branch\"] + months + [\"total_calc\"]].head(10), clean_monthly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa187309-14b5-419d-8a3c-32c1e8bef59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "\n",
    "# add missing months if not present\n",
    "for m in [\"oct\",\"nov\",\"dec\"]:\n",
    "    if m not in clean_monthly.columns:\n",
    "        clean_monthly[m] = np.nan\n",
    "\n",
    "# make year an integer type (nullable)\n",
    "clean_monthly[\"year\"] = pd.to_numeric(clean_monthly[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# make sure month columns are numeric\n",
    "for m in months:\n",
    "    clean_monthly[m] = pd.to_numeric(clean_monthly[m], errors=\"coerce\")\n",
    "\n",
    "# recompute total (safe)\n",
    "clean_monthly[\"total_calc\"] = clean_monthly[months].sum(axis=1, skipna=True)\n",
    "\n",
    "clean_monthly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3e172-1b96-48e1-94cf-5b9da3c068dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_branch(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = s.replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    s = \" \".join(s.split())  # collapse spaces\n",
    "    return s.strip()\n",
    "\n",
    "clean_monthly[\"branch_norm\"] = clean_monthly[\"branch\"].apply(normalize_branch).str.lower()\n",
    "clean_monthly[[\"branch\",\"branch_norm\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb6d44-d797-4a99-b4a9-b110cfdd7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_monthly.shape\n",
    "clean_monthly[\"year\"].value_counts(dropna=False).sort_index()\n",
    "clean_monthly[\"branch_norm\"].nunique(), clean_monthly[\"branch\"].nunique()\n",
    "clean_monthly.isna().sum().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64981ec-a2e9-4178-b2a4-98661e075563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "OUT_DIR = Path(\"../outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "out1 = OUT_DIR / \"clean_monthly_sales_file1.csv\"\n",
    "clean_monthly.to_csv(out1, index=False)\n",
    "print(\"Saved:\", out1.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3eb64-5f10-4e9b-81ec-7a56c9d12544",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "\n",
    "keep_cols = [\"year\", \"branch\", \"branch_norm\"] + months + [\"total_calc\"]\n",
    "\n",
    "clean_monthly = clean_monthly[keep_cols].copy()\n",
    "\n",
    "clean_monthly.shape, clean_monthly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264e0a0-e2d9-47f8-8ffa-9cb6f1b6c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_monthly.isna().sum().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f8097-7127-41fb-b413-80194da96731",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = OUT_DIR / \"clean_monthly_sales_file1.csv\"\n",
    "clean_monthly.to_csv(out1, index=False)\n",
    "print(\"Saved:\", out1.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f21459-bbe3-4035-a6d2-bfe351093d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd8fc9-1e78-4021-b2a3-f87943ed0c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
